{"cells":[{"cell_type":"markdown","metadata":{"id":"G9WoQc6gotEd"},"source":["# A Guide to Market Basket Analysis in PySpark üõí\n","\n","This tutorial introduces **frequent itemset mining** and **association rule mining**, two fundamental techniques for uncovering meaningful relationships within large datasets. A classic example is \"market basket analysis,\" where we analyze customer transactions to identify products that are frequently purchased together. For instance, we might find that customers who buy tortilla chips also tend to buy salsa. We'll cover two algorithms:\n","\n","1.  **A Priori**: A classic algorithm that we'll build from scratch to understand the core logic.\n","2.  **FP-Growth**: A modern, highly scalable algorithm that is built directly into Spark's Machine Learning library (MLlib).\n","\n","**Credits**\n","\n","This tutorial is adapted from [MACS40123 Fall24 Frequent Itemsets Tutorial](https://github.com/macs40123-f24/course-materials/blob/main/in-class-activities/02_pagerank_association/freq_itemset.ipynb).\n","\n","**Compatibility**\n","\n","| Platform                      | Compatible | Recommended | Notes                                                                                                                                    |\n","| ----------------------------- | ---------- | ----------- | ---------------------------------------------------------------------------------------------------------------------------------------- |\n","| **Local (e.g., 16GB laptop)** | ‚úÖ Yes     | ‚úÖ Yes      | \tUse the sampled dataset due to memory limits. |\n","| **Google Colab**              | ‚úÖ Yes     | ‚úÖ Yes  |  Limited compatibility with a sampled dataset.                                                    |\n","| **Midway3 Login Node**        | ‚úÖ Yes      | ‚ùå No       | Not Recommended. Avoid running heavy computations on shared login nodes.    |\n","| **Midway3 Compute Node**      | ‚úÖ Yes     | ‚úÖ Yes      | Scales effectively; tested with 10 cores and 64GB memory on the `amd` partition. |\n","\n","## Set up the Spark Environment\n","\n","We will begin by creating a SparkSession and defining a small sample dataset, where each row represents a \"basket\" (or transaction) containing a list of items.\n","\n","In this example, we will use a **minimum support count** of `s = 3`, mining itemsets that appear in at least 3 different baskets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WzYf6yKvBnm8"},"outputs":[],"source":["import os\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from itertools import combinations\n","\n","# Initialize Spark Session\n","spark = SparkSession.builder.appName(\"FrequentItemsetMining\").getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7myFJvaWotEf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758554689574,"user_tz":300,"elapsed":11651,"user":{"displayName":"Peter Zhang","userId":"01014316854815802369"}},"outputId":"ad927006-d202-4f50-ae38-909cdb4e8b1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["+---+-----------------------------------------------------------------------------------------------+\n","|id |basket                                                                                         |\n","+---+-----------------------------------------------------------------------------------------------+\n","|0  |[cat, and, dog, bits]                                                                          |\n","|1  |[yahoo, news, claims, a, cat, mated, with, dog, and, produced, viable, offspring]              |\n","|2  |[cat, killer, likely, is, a, big, dog]                                                         |\n","|3  |[professional, free, advice, on, dog, training, puppy]                                         |\n","|4  |[cat, and, kitten, training, behavior]                                                         |\n","|5  |[dog, &, cat, provides, training, in, eugene, oregon]                                          |\n","|6  |[dog, and, cat, is, a, slang, term, used, by, police, officers, for, male-female, relationship]|\n","|7  |[shop, for, your, show, dog, grooming, and, pet, supplies]                                     |\n","+---+-----------------------------------------------------------------------------------------------+\n","\n"]}],"source":["# Sample data representing 8 different baskets\n","# Note that this is a toy example for demonstration purpose only. In real-world text representation, please remember to remove stopwords first.\n","data = [\n","    (0, ['cat', 'and', 'dog', 'bits']),\n","    (1, ['yahoo', 'news', 'claims', 'a', 'cat', 'mated', 'with', 'dog', 'and', 'produced', 'viable', 'offspring']),\n","    (2, ['cat', 'killer', 'likely', 'is', 'a', 'big', 'dog']),\n","    (3, ['professional', 'free', 'advice', 'on', 'dog', 'training', 'puppy']),\n","    (4, ['cat', 'and', 'kitten', 'training', 'behavior']),\n","    (5, ['dog', '&', 'cat', 'provides', 'training', 'in', 'eugene', 'oregon']),\n","    (6, ['dog', 'and', 'cat', 'is', 'a', 'slang', 'term', 'used', 'by', 'police', 'officers', 'for', 'male-female', 'relationship']),\n","    (7, ['shop', 'for', 'your', 'show', 'dog', 'grooming', 'and', 'pet', 'supplies'])\n","]\n","\n","\n","df = spark.createDataFrame(data, [\"id\", \"basket\"])\n","df.show(truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"ahem2GGeotEg"},"source":["---\n","\n","## The A Priori Algorithm: A Step-by-Step Walkthrough\n","\n","The A Priori algorithm identifies frequent itemsets through an interative process -- starting with individual items and progressively expanding to larger sets. Its key insight, the **A Priori Principle**, is simple but powerful:\n","\n","> **If an itemset is frequent, then all of its subsets must also be frequent.**\n","\n","This principal enables significant pruning of candidate itemsets. For example, if `{bread}` is not a frequent item, there's no need to calculate the support for `{bread, butter}`, since it cannot be frequent either.\n","\n","### Step 1: Find Frequent Singletons (L‚ÇÅ)\n","\n","We start by counting the frequency of every individual item and only record those that meet the minimum support threshold of `s=3`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ENdTYBf4otEg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758554691721,"user_tz":300,"elapsed":2149,"user":{"displayName":"Peter Zhang","userId":"01014316854815802369"}},"outputId":"36873f85-3221-4e0a-a83d-a198b3d1b6bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Frequent Singletons (L1):\n","{('cat',): 6, ('a',): 3, ('training',): 3, ('and',): 5, ('dog',): 7}\n"]}],"source":["# Set the support threshold\n","s = 3\n","\n","# 1. flatMap to create a (item, 1) pair for each item in each basket\n","# 2. reduceByKey to sum the counts for each item\n","# 3. filter to keep only items with a count >= s\n","L1 = (\n","    df.rdd.flatMap(lambda row: [((item,), 1) for item in row.basket])\n","    .reduceByKey(lambda x, y: x + y)\n","    .filter(lambda x: x[1] >= s)\n","    .collect()\n",")\n","\n","# We store frequent itemsets in a dictionary for easy lookup\n","Lk_1 = dict(L1)\n","print(\"Frequent Singletons (L1):\")\n","print(Lk_1)"]},{"cell_type":"markdown","metadata":{"id":"s1nj8gvjotEh"},"source":["### Step 2: Find Frequent Pairs (L‚ÇÇ)\n","\n","The next step is to find frequent pairs:\n","\n","1.  **Generate Candidates (C‚ÇÇ):** Create all possible pairs from each basket.\n","2.  **Prune:** Keep only those candidate pairs where _both_ individual items are frequent singletons (in L‚ÇÅ). This is the A Priori principle in action\\!\n","3.  **Count & Filter:** Count the support for the selected candidates and keep the frequent ones.\n","\n","<!-- end list -->\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K32OGOeMotEh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758554692641,"user_tz":300,"elapsed":921,"user":{"displayName":"Peter Zhang","userId":"01014316854815802369"}},"outputId":"aba1ccda-b6e6-43c8-9693-b26d270443ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Frequent Pairs (L2):\n","{('and', 'dog'): 4, ('a', 'cat'): 3, ('and', 'cat'): 4, ('cat', 'dog'): 5, ('a', 'dog'): 3}\n"]}],"source":["# Lk_1 is our dictionary of frequent singletons from the previous step\n","\n","# 1. flatMap to generate all 2-item combinations from each basket\n","# 2. map to create a (pair, subsets) tuple. e.g., (('cat', 'dog'), {('cat',), ('dog',)})\n","# 3. filter to keep only pairs whose subsets are all in Lk_1\n","# 4. map to prepare for counting: (('cat', 'dog'), 1)\n","# 5. reduceByKey to count and filter to find L2\n","C2 = (\n","    df.rdd.flatMap(lambda row: [i for i in combinations(row.basket, 2)])\n","    .map(lambda pair: (pair, {tuple(sorted(i)) for i in combinations(pair, 1)}))\n","    .filter(lambda x: x[1].issubset(Lk_1.keys()))\n","    .map(lambda x: (tuple(sorted(x[0])), 1))\n",")\n","\n","L2 = C2.reduceByKey(lambda x, y: x + y).filter(lambda x: x[1] >= s).collect()\n","\n","L2 = dict(L2)\n","print(\"Frequent Pairs (L2):\")\n","print(L2)"]},{"cell_type":"markdown","metadata":{"id":"u7gSs3NbotEh"},"source":["### Step 3: Find Frequent Triplets (L‚ÇÉ)\n","\n","We repeat the process for 3-item sets, using the frequent pairs (L‚ÇÇ) to prune the candidates.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BR7FE0XnotEh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758554693442,"user_tz":300,"elapsed":802,"user":{"displayName":"Peter Zhang","userId":"01014316854815802369"}},"outputId":"68a59220-202f-4372-c2cd-e1c1ad6974e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Frequent Triplets (L3):\n","{('and', 'cat', 'dog'): 3, ('a', 'cat', 'dog'): 3}\n"]}],"source":["# L2 is our dictionary of frequent pairs from the previous step\n","\n","C3 = (\n","    df.rdd.flatMap(lambda row: [i for i in combinations(row.basket, 3)])\n","    .map(\n","        lambda triplet: (triplet, {tuple(sorted(i)) for i in combinations(triplet, 2)})\n","    )\n","    .filter(lambda x: x[1].issubset(L2.keys()))\n","    .map(lambda x: (tuple(sorted(x[0])), 1))\n",")\n","L3 = C3.reduceByKey(lambda x, y: x + y).filter(lambda x: x[1] >= s).collect()\n","\n","L3 = dict(L3)\n","print(\"Frequent Triplets (L3):\")\n","print(L3)"]},{"cell_type":"markdown","metadata":{"id":"drBB6fF8otEi"},"source":["### Bringing it all Together: define the `apriori` algorithm\n","\n","We can consolidate this logic into a single function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMztqwacotEi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758554698844,"user_tz":300,"elapsed":5404,"user":{"displayName":"Peter Zhang","userId":"01014316854815802369"}},"outputId":"70b20551-eb54-4253-b5d8-7bae99663274"},"outputs":[{"output_type":"stream","name":"stdout","text":["All Frequent Itemsets:\n","{('cat',): 6, ('a',): 3, ('training',): 3, ('and',): 5, ('dog',): 7, ('and', 'dog'): 4, ('a', 'cat'): 3, ('and', 'cat'): 4, ('cat', 'dog'): 5, ('a', 'dog'): 3, ('and', 'cat', 'dog'): 3, ('a', 'cat', 'dog'): 3}\n"]}],"source":["def apriori(df, support=3):\n","    \"\"\"\n","    A basic implementation of the A Priori algorithm in PySpark.\n","    \"\"\"\n","    # Find frequent singletons\n","    L1 = (\n","        df.rdd.flatMap(lambda x: [((i,), 1) for i in x.basket])\n","        .reduceByKey(lambda x, y: x + y)\n","        .filter(lambda x: x[1] >= support)\n","        .collect()\n","    )\n","    Lk_1 = dict(L1)\n","    freq_itemsets = (\n","        Lk_1.copy()\n","    )  # Use .copy() to avoid modifying the dict while iterating\n","\n","    # Find frequent doubletons and higher\n","    k = 2\n","    while Lk_1:\n","        Lk = (\n","            df.rdd.flatMap(lambda x: [i for i in combinations(x.basket, k)])\n","            .map(lambda x: (x, set([tuple(sorted(i)) for i in combinations(x, k - 1)])))\n","            .filter(lambda x: set(x[1]).issubset(Lk_1.keys()))\n","            .map(lambda x: (tuple(sorted(x[0])), 1))\n","            .reduceByKey(lambda x, y: x + y)\n","            .filter(lambda x: x[1] >= support)\n","            .collect()\n","        )\n","\n","        if not Lk:  # Break if no new frequent itemsets are found\n","            break\n","\n","        Lk_1 = dict(Lk)\n","        freq_itemsets.update(Lk_1)\n","        k += 1\n","\n","    return freq_itemsets\n","\n","\n","# Run the function and see the final result\n","all_freq_itemsets = apriori(df, support=3)\n","print(\"All Frequent Itemsets:\")\n","print(all_freq_itemsets)\n","\n","# Note: itemsets are represented with tuple data structure, no matter how many elements are contained in the itemset."]},{"cell_type":"markdown","metadata":{"id":"UCZ8r462otEi"},"source":["---\n","\n","## From Frequent Itemsets to Association Rules\n","\n","Once we've identified the frequent itemsets, we can generate association rules in the form of  A‚ÜíB , where A is the **antecedent** and B is the **consequent**, and we will evaluate the strength of each rule using **confidence** and **lift**.\n","\n","- **Confidence**: The likelihood of observing item B when item A is present. A confidence of 80% for `chips -> salsa` means that 80% of customers who bought chips also bought salsa.\n","\n","  $$Confidence(A \\to B) = \\frac{Support(A \\cup B)}{Support(A)}$$\n","\n","- **Lift**: Measures how much **more** likely we will observe item B when item A is present, compared to the baseline probability of B occurring on its own.\n","\n","\n","    $$Lift(A \\to B) = \\frac{Support(A \\cup B)}{Support(A) \\times Support(B)} $$\n","\n","\n","  - `Lift > 1`: A and B have a positive correlation (they appear together more than expected).\n","  - `Lift < 1`: A and B have a negative correlation.\n","  - `Lift = 1`: A and B are independent.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBAnEi5RotEi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758554699732,"user_tz":300,"elapsed":890,"user":{"displayName":"Peter Zhang","userId":"01014316854815802369"}},"outputId":"2e140743-1df2-422f-c393-ed6e6b5afd06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Antecedent           -> Consequent      | Confidence   | Lift\n","-----------------------------------------------------------------\n","('and',)             -> ('dog',)        | 0.800        | 0.914\n","('a',)               -> ('cat',)        | 1.000        | 1.333\n","('and',)             -> ('cat',)        | 0.800        | 1.067\n","('cat',)             -> ('dog',)        | 0.833        | 0.952\n","('a',)               -> ('dog',)        | 1.000        | 1.143\n","('a',)               -> ('cat', 'dog')  | 1.000        | 1.600\n","('a', 'cat')         -> ('dog',)        | 1.000        | 1.143\n","('a', 'dog')         -> ('cat',)        | 1.000        | 1.333\n"]}],"source":["def generate_association_rules(freq_itemsets, total_baskets, confidence_threshold=0.8):\n","  \"\"\"\n","  Calculate association rules based on the confidence_threshold.\n","  \"\"\"\n","    rules = []\n","    for itemset, support in freq_itemsets.items():\n","        if len(itemset) < 2:\n","            continue\n","\n","        # Generate all non-empty proper subsets of the itemset\n","        subsets = [s for i in range(1, len(itemset)) for s in combinations(itemset, i)]\n","\n","        for antecedent in subsets:\n","            antecedent = tuple(sorted(antecedent))\n","            consequent = tuple(sorted(set(itemset) - set(antecedent)))\n","\n","            # This check is crucial\n","            if antecedent in freq_itemsets and consequent in freq_itemsets:\n","                antecedent_support = freq_itemsets.get(antecedent, 0)\n","\n","                if antecedent_support > 0:\n","                    confidence = support / antecedent_support\n","\n","                    if confidence >= confidence_threshold:\n","                        # Calculate lift\n","                        consequent_support = freq_itemsets.get(consequent, 0)\n","                        lift = (support * total_baskets) / (\n","                            antecedent_support * consequent_support\n","                        )\n","                        rules.append(((antecedent, consequent, confidence, lift)))\n","\n","    return rules\n","\n","\n","# Get the total number of baskets\n","total_baskets = df.count()\n","\n","# Generate and print the rules\n","association_rules = generate_association_rules(\n","    all_freq_itemsets, total_baskets, confidence_threshold=0.8\n",")\n","\n","# Print in a readable format\n","print(f\"{'Antecedent':<20} -> {'Consequent':<15} | {'Confidence':<12} | {'Lift'}\")\n","print(\"-\" * 65)\n","for rule in association_rules:\n","    ant, con, conf, lift = rule\n","    print(f\"{str(ant):<20} -> {str(con):<15} | {conf:<12.3f} | {lift:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"eaHLxpwbotEi"},"source":["This reveals a strong rule: customers who \"buy\" `('a', 'dog')` also \"buy\" `('cat',)` with 100% confidence.\n","\n","---\n","\n","## **Scalability Issues** of the A Priori Implementation ‚ö†Ô∏è\n","\n","While the self-defined apriori function works for small datasets, it is unsuitable to scale to large datasets for the following reasons:\n","\n","1.  **Candidate Generation Bottleneck**: The step `flatMap(lambda x: [i for i in combinations(x.basket, k)])` is incredibly expensive. It generates a massive number of candidate itemsets on the Spark executors for every pass.\n","2.  **Multiple Data Passes**: The algorithm requires a full pass over the entire dataset for each `k` (i.e., for pairs, triplets, etc.). For large datasets, this I/O is very slow.\n","3.  **Driver Memory Overload**: The `.collect()` action at each step brings the _entire list of frequent k-itemsets_ back to the driver node. If you have millions of frequent pairs, this will easily crash the driver with an OutOfMemoryError. This is a classic Spark anti-pattern.\n","\n","To fix this, one would need a much more complex implementation that keeps candidate sets distributed on the cluster. But there's a better way\\!\n","\n","### A Better Way: **FP-Growth** üöÄ\n","\n","Fortunately, we don't need to write our own algorithms. Spark MLlib has a parallel and highly scalable implementation of **FP-Growth**, which avoids the candidate generation bottleneck of A Priori. It uses a clever tree-based data structure (an FP-Tree) to find frequent itemsets in just two passes over the data.\n","\n","Let's apply it on our small dataset first.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"noF-jcd6otEi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758554704625,"user_tz":300,"elapsed":4895,"user":{"displayName":"Peter Zhang","userId":"01014316854815802369"}},"outputId":"22ab9505-0a92-4326-e510-2316645b4914"},"outputs":[{"output_type":"stream","name":"stdout","text":["Frequent Itemsets found by FP-Growth:\n","+---------------+----+\n","|          items|freq|\n","+---------------+----+\n","|          [dog]|   7|\n","|          [cat]|   6|\n","|          [and]|   5|\n","|     [cat, dog]|   5|\n","|     [and, cat]|   4|\n","|     [and, dog]|   4|\n","|     [training]|   3|\n","|[and, cat, dog]|   3|\n","|            [a]|   3|\n","|       [a, cat]|   3|\n","|  [a, cat, dog]|   3|\n","|       [a, dog]|   3|\n","+---------------+----+\n","\n","Association Rules found by FP-Growth:\n","+----------+----------+------------------+------------------+-------+\n","|antecedent|consequent|        confidence|              lift|support|\n","+----------+----------+------------------+------------------+-------+\n","|  [a, cat]|     [dog]|               1.0|1.1428571428571428|  0.375|\n","|  [a, dog]|     [cat]|               1.0|1.3333333333333333|  0.375|\n","|       [a]|     [cat]|               1.0|1.3333333333333333|  0.375|\n","|       [a]|     [dog]|               1.0|1.1428571428571428|  0.375|\n","|     [cat]|     [dog]|0.8333333333333334|0.9523809523809524|  0.625|\n","|     [and]|     [cat]|               0.8|1.0666666666666667|    0.5|\n","|     [and]|     [dog]|               0.8|0.9142857142857144|    0.5|\n","+----------+----------+------------------+------------------+-------+\n","\n"]}],"source":["from pyspark.ml.fpm import FPGrowth\n","\n","# FPGrowth requires the input column to be named 'items'\n","fp_growth = FPGrowth(itemsCol=\"basket\", minSupport=s / total_baskets, minConfidence=0.8)\n","model = fp_growth.fit(df)\n","\n","# Display frequent itemsets\n","print(\"Frequent Itemsets found by FP-Growth:\")\n","model.freqItemsets.sort(\"freq\", ascending=False).show()\n","\n","# Display generated association rules\n","print(\"Association Rules found by FP-Growth:\")\n","model.associationRules.sort(\"confidence\", ascending=False).show()"]},{"cell_type":"markdown","metadata":{"id":"wUQBUV6notEi"},"source":["As you can see, the built-in `FPGrowth` model finds the same itemsets and rules with much less code and greater efficiency.\n","\n","---\n","\n","## Real-World Case Study: Analyzing Instacart Orders ü•ëüçìüçå\n","\n","Now let's apply FP-Growth to a large real-world dataset containing over 3 million Instacart orders. The goal is to discover food purchasing patterns that may reveal insights into recipes, dietary habits, or broader cultural trends.\n","\n","_Note: In this demo, we only sample 1% of the data to ensure it runs quickly in a standard environment._\n"]},{"cell_type":"code","source":["# If you are using Midway, run this code\n","# DATA_DIR = \"../datasets/instacart-3m\""],"metadata":{"id":"RzGuTpqOCDuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# If you are using Google Colab, run this code\n","import kagglehub\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"psparks/instacart-market-basket-analysis\")\n","\n","DATA_DIR = path\n","print(\"Path to dataset files:\", path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OHkpGjnZBySd","executionInfo":{"status":"ok","timestamp":1758554785925,"user_tz":300,"elapsed":895,"user":{"displayName":"Peter Zhang","userId":"01014316854815802369"}},"outputId":"7160e8a7-9554-4999-fd60-30717f26362c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/psparks/instacart-market-basket-analysis/versions/1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8bwSwPGtotEi"},"outputs":[],"source":["# Load the data\n","# Make sure the CSV files are accessible in your environment\n","instacart_orders = spark.read.csv(\n","    os.path.join(DATA_DIR, \"order_products__prior.csv\"), header=True, inferSchema=True\n",")\n","product_codes = spark.read.csv(\n","    os.path.join(DATA_DIR, \"products.csv\"), header=True, inferSchema=True\n",")\n","\n","# Aggregate products into baskets by order_id\n","instacart_baskets = instacart_orders.groupBy(\"order_id\").agg(\n","    F.collect_list(\"product_id\").alias(\"items\")\n",")\n","\n","# For demo purposes, sample down to 1% of the data\n","instacart_baskets_sample = instacart_baskets.sample(0.01, seed=40123)\n","instacart_baskets_sample.cache()  # Cache for faster access\n","\n","# Configure and run FP-Growth\n","# Support = 3.2m orders * 1% sample * 0.001 support = ~32 orders\n","fp = FPGrowth(itemsCol=\"items\", minSupport=0.001, minConfidence=0.5)\n","fpm = fp.fit(instacart_baskets_sample)"]},{"cell_type":"markdown","metadata":{"id":"esFApZ5WotEj"},"source":["### Discovery 1: What are the most frequently purchased items?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2AJpxDRotEj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758555042058,"user_tz":300,"elapsed":69924,"user":{"displayName":"Peter Zhang","userId":"01014316854815802369"}},"outputId":"dfff0f00-4f0e-49cd-f8e5-e50c20381628"},"outputs":[{"output_type":"stream","name":"stdout","text":["Top 10 Most Frequent Items:\n","+-------+----+----------+----------------------+--------+-------------+\n","|items  |freq|product_id|product_name          |aisle_id|department_id|\n","+-------+----+----------+----------------------+--------+-------------+\n","|[24852]|4806|24852     |Banana                |24      |4            |\n","|[13176]|3845|13176     |Bag of Organic Bananas|24      |4            |\n","|[21137]|2623|21137     |Organic Strawberries  |24      |4            |\n","|[21903]|2472|21903     |Organic Baby Spinach  |123     |4            |\n","|[47209]|2161|47209     |Organic Hass Avocado  |24      |4            |\n","|[47766]|1714|47766     |Organic Avocado       |24      |4            |\n","|[47626]|1521|47626     |Large Lemon           |24      |4            |\n","|[26209]|1419|26209     |Limes                 |24      |4            |\n","|[16797]|1405|16797     |Strawberries          |24      |4            |\n","|[27966]|1357|27966     |Organic Raspberries   |123     |4            |\n","+-------+----+----------+----------------------+--------+-------------+\n","only showing top 10 rows\n","\n"]}],"source":["# Join with product names for readability\n","# This might take a minute\n","freq_items_with_names = fpm.freqItemsets.join(\n","    product_codes, fpm.freqItemsets.items[0] == product_codes.product_id\n",")\n","print(\"Top 10 Most Frequent Items:\")\n","freq_items_with_names.sort(\"freq\", ascending=False).show(10, truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"ppC9isfnotEj"},"source":["### Discovery 2: What purchasing patterns could we discover?\n","\n","Let's review the generated association rules and join them with product names.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QOdh_r76otEj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758555114982,"user_tz":300,"elapsed":72925,"user":{"displayName":"Peter Zhang","userId":"01014316854815802369"}},"outputId":"d00a3a08-8eda-44ff-b330-15e193612b65"},"outputs":[{"output_type":"stream","name":"stdout","text":["High-Confidence Association Rules (Lift > 2) with Full Item Lists:\n","+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------+------------------+------------------+\n","|antecedent_name                                                                                         |consequent_name                                        |confidence        |lift              |\n","+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------+------------------+------------------+\n","|[Non Fat Raspberry Yogurt, Vanilla Skyr Nonfat Yogurt]                                                  |[Icelandic Style Skyr Blueberry Non-fat Yogurt]        |0.6938775510204082|117.95918367346938|\n","|[Sparkling Water Berry, Lime Sparkling Water]                                                           |[Sparkling Water Grapefruit]                           |0.6842105263157895|26.831126896997095|\n","|[Peach Pear Flavored Sparkling Water, Sparkling Lemon Water]                                            |[Sparkling Water Grapefruit]                           |0.6666666666666666|26.143149284253578|\n","|[Almond Milk Peach Yogurt]                                                                              |[Almond Milk Strawberry Yogurt]                        |0.6538461538461539|294.3228602383532 |\n","|[Peach Pear Flavored Sparkling Water, Lime Sparkling Water]                                             |[Sparkling Water Grapefruit]                           |0.6538461538461539|25.64039641340255 |\n","|[Total 2% Lowfat Greek Strained Yogurt With Blueberry, Total 2% Lowfat Greek Strained Yogurt with Peach]|[Total 2% with Strawberry Lowfat Greek Strained Yogurt]|0.6166666666666667|65.26048565121414 |\n","|[Sparkling Water Berry, Sparkling Lemon Water]                                                          |[Sparkling Water Grapefruit]                           |0.6153846153846154|24.13213780084946 |\n","|[Almond Milk Blueberry Yogurt]                                                                          |[Almond Milk Strawberry Yogurt]                        |0.6111111111111112|275.08607198748047|\n","|[Blueberry on the Bottom Nonfat Greek Yogurt]                                                           |[Strawberry on the Bottom Nonfat Greek Yogurt]         |0.5964912280701754|204.98773816261084|\n","|[Seedless Red Grapes, Organic Fuji Apple]                                                               |[Banana]                                               |0.5846153846153846|3.887704471974135 |\n","|[Pure Sparkling Water, Sparkling Lemon Water]                                                           |[Sparkling Water Grapefruit]                           |0.576271186440678 |22.598315482998856|\n","|[Organic Navel Orange, Organic Hass Avocado]                                                            |[Bag of Organic Bananas]                               |0.5633802816901409|4.682869649627283 |\n","|[Organic D'Anjou Pears, Organic Raspberries]                                                            |[Bag of Organic Bananas]                               |0.5538461538461539|4.603621086325898 |\n","|[Honeycrisp Apple, Cucumber Kirby]                                                                      |[Banana]                                               |0.5342465753424658|3.5527508422690817|\n","|[Organic Raspberries, Organic Hass Avocado, Organic Strawberries]                                       |[Bag of Organic Bananas]                               |0.5316455696202531|4.419087751641948 |\n","|[Organic Cucumber, Organic Lemon]                                                                       |[Bag of Organic Bananas]                               |0.5232558139534884|4.3493513170230145|\n","|[Organic Raspberries, Organic Hass Avocado]                                                             |[Bag of Organic Bananas]                               |0.5209125475285171|4.329873867103097 |\n","|[Unsweetened Almondmilk, Organic Hass Avocado]                                                          |[Bag of Organic Bananas]                               |0.5               |4.156046814044213 |\n","|[Seedless Red Grapes, Strawberries]                                                                     |[Banana]                                               |0.5               |3.325010403662089 |\n","|[Nonfat Icelandic Style Strawberry Yogurt]                                                              |[Icelandic Style Skyr Blueberry Non-fat Yogurt]        |0.5               |85.0              |\n","+--------------------------------------------------------------------------------------------------------+-------------------------------------------------------+------------------+------------------+\n","\n"]}],"source":["# Join rules with product names\n","rules = fpm.associationRules\n","\n","# 1. Create a lookup table for antecedent names\n","# Explode the array of product IDs, join with product names, then group back to a list of names\n","ant_lookup = rules.select(\"antecedent\").distinct() \\\n","    .withColumn(\"product_id\", F.explode(\"antecedent\")) \\\n","    .join(product_codes, \"product_id\") \\\n","    .groupBy(\"antecedent\") \\\n","    .agg(F.collect_list(\"product_name\").alias(\"antecedent_name\"))\n","\n","# 2. Create a lookup table for consequent names\n","con_lookup = rules.select(\"consequent\").distinct() \\\n","    .withColumn(\"product_id\", F.explode(\"consequent\")) \\\n","    .join(product_codes, \"product_id\") \\\n","    .groupBy(\"consequent\") \\\n","    .agg(F.collect_list(\"product_name\").alias(\"consequent_name\"))\n","\n","# 3. Join the original rules with both lookup tables\n","rules_with_names = rules.join(ant_lookup, \"antecedent\") \\\n","    .join(con_lookup, \"consequent\") \\\n","    .select(\"antecedent_name\", \"consequent_name\", \"confidence\", \"lift\")\n","\n","print(\"High-Confidence Association Rules (Lift > 2) with Full Item Lists:\")\n","rules_with_names.filter(\"lift > 2\").sort(\"confidence\", ascending=False).show(n=30, truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"rhA23II1otEj"},"source":["We can observe rules that reveal common purchasing patterns. For example, customers who buy `Raspberry Yogurt` and `Vanilla Yogurt` are also very likely to buy `Blueberry Yogurt`.\n","\n","### Discovery 3: The \"Organic Fruit Bowl\" Grammar\n","\n","Looking more closely, one of the high-lift rules is `{Organic Hass Avocado, Organic Raspberries, Organic Strawberries} -> {Bag of Organic Bananas}`. This is like uncovering the _grammar_ of an organic fruit salad!\n","\n","## Conclusion\n","\n","This tutorial walked through the process of manually implementing the A Priori algorithm to leveraging Spark's highly optimized FP-Growth model.\n","\n","**Key Takeaways:**\n","\n","- **A Priori** provides the fundamental understanding of how frequent itemset mining works, but its candidate generation process limits scalability.\n","- **FP-Growth** is the industry-standard, scalable approach for market basket analysis in Spark, efficiently processing massive datasets in just two passes.\n","- Applying these techniques to real-world data can reveal compelling and actionable insights into consumer behavior -- from identifying common recipe combinations to understanding broader dietary trends.\n"]},{"cell_type":"markdown","metadata":{"id":"5ShHNx2uBnnH"},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.11"}},"nbformat":4,"nbformat_minor":0}